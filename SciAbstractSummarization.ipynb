{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Abstractive Summarization Using Transformers\n",
        "## Project Code - Successful Implementation\n",
        "### Sai Srikar Emani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC4Cx002lOn8"
      },
      "source": [
        "# Environment Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx43N06A8iUh",
        "outputId": "75090e3e-0369-4478-d8a1-b34e967df722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX4WdXO_GZQi",
        "outputId": "4f38f8fb-555d-4c11-8561-d6a389a5183a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw4pMR09Gltw"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp '/content/drive/MyDrive/Scientific Abstract Summarization/kaggle.json' ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9Wv8EJNGsBN"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/My Drive/Scientific Abstract Summarization/archive.zip' ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSX9G4FAGxdg",
        "outputId": "c51ef254-301d-4f12-ce9f-ee70cb6a0ce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset extracted!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Extract the dataset\n",
        "with zipfile.ZipFile(\"archive.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"arxiv_dataset\")\n",
        "\n",
        "print(\"Dataset extracted!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9vOLT9ZG1Eg",
        "outputId": "2733cd48-83db-4ec1-a186-d95965ef557f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arxiv-metadata-oai-snapshot.json\n"
          ]
        }
      ],
      "source": [
        "!ls arxiv_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRVcRnMSG-hi",
        "outputId": "5f210470-0de2-447b-e447-30697223e813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total entries loaded: 50000\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON file\n",
        "file_path = \"arxiv_dataset/arxiv-metadata-oai-snapshot.json\"\n",
        "\n",
        "# Read and limit the number of records to 50,000\n",
        "with open(file_path, 'r') as f:\n",
        "    data = [json.loads(line) for i, line in enumerate(f) if i < 50000]\n",
        "\n",
        "# Check the number of entries\n",
        "print(f\"Total entries loaded: {len(data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_QJbalqkljq"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5idjqvyZHAFj",
        "outputId": "4b38b45f-ad35-463e-d98e-9f207650051c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total processed entries: 50000\n",
            "                                          input_text  \\\n",
            "0    A fully differential calculation in perturba...   \n",
            "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
            "2    The evolution of Earth-Moon system is descri...   \n",
            "3    We show that a determinant of Stirling cycle...   \n",
            "4    In this paper we show how to compute the $\\L...   \n",
            "\n",
            "                                         target_text  \n",
            "0  Calculation of prompt diphoton production cros...  \n",
            "1           Sparsity-certifying Graph Decompositions  \n",
            "2  The evolution of the Earth-Moon system based o...  \n",
            "3  A determinant of Stirling cycle numbers counts...  \n",
            "4  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Extract relevant fields (titles and abstracts)\n",
        "processed_data = []\n",
        "for entry in data:\n",
        "    if 'title' in entry and 'abstract' in entry:  # Ensure both fields exist\n",
        "        processed_data.append({\n",
        "            \"input_text\": entry[\"abstract\"],\n",
        "            \"target_text\": entry[\"title\"]\n",
        "        })\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(processed_data)\n",
        "\n",
        "# Check the processed data\n",
        "print(f\"Total processed entries: {len(df)}\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPxv1sXiHCYv",
        "outputId": "1d32a91e-47d9-4422-addd-71c89adecd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train, validation, and test sets saved as CSV!\n"
          ]
        }
      ],
      "source": [
        "# Split into train, validation, and test sets\n",
        "train_df = df[:40000]  # First 40,000 for training\n",
        "val_df = df[40000:45000]  # Next 5,000 for validation\n",
        "test_df = df[45000:]  # Final 5,000 for testing\n",
        "\n",
        "# Save as CSV files\n",
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "val_df.to_csv(\"val.csv\", index=False)\n",
        "test_df.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "print(\"Train, validation, and test sets saved as CSV!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_fFj-cUHILs"
      },
      "outputs": [],
      "source": [
        "!mv train.csv '/content/drive/My Drive/Scientific Abstract Summarization/'\n",
        "!mv val.csv '/content/drive/My Drive/Scientific Abstract Summarization/'\n",
        "!mv test.csv '/content/drive/My Drive/Scientific Abstract Summarization/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYXeNAckHJ2_",
        "outputId": "377fb17b-dd90-4939-aef5-175484383758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vte7GPKsHLDT",
        "outputId": "a991927e-67d5-407a-e73e-f41e15e1785a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data size: 40000\n",
            "Validation data size: 5000\n",
            "Test data size: 5000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Scientific Abstract Summarization/train.csv\")\n",
        "val_df = pd.read_csv(\"/content/drive/MyDrive/Scientific Abstract Summarization/val.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Scientific Abstract Summarization/test.csv\")\n",
        "\n",
        "# Display dataset information\n",
        "print(\"Train data size:\", len(train_df))\n",
        "print(\"Validation data size:\", len(val_df))\n",
        "print(\"Test data size:\", len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274,
          "referenced_widgets": [
            "49a418a2bbcc461dbf52ad194db27c14",
            "abbafe1804d5406eb9fee475f9876794",
            "778b2d57370f4d0a9bbdb56582b3761a",
            "3a3d805e7c75403db77201ea34e0f7d1",
            "ac351ec33b994f4c9655cefa021f95b8",
            "36acdffb2bd747d0ba213737dac91298",
            "da756576955f4ef7a598cd3f500a96f4",
            "f72916c0369245c79dbc015247288b52",
            "6190d91fe7d748bb921ae6e7ce4054a8",
            "0a000c1185c54521a9e5a505285bd38b",
            "9f12dda087bc4996ab951930220e72c3",
            "08f69bfff88e4d519623a34389959f2a",
            "ed0c9f8b82cf44108aa3ccac2418e96d",
            "acff8a28306b49abab1542cc6eaa955c",
            "dcd981f091d6462fb45827d4aaca4506",
            "0219f4c1d0b74e9a978a6a4f18335737",
            "5bf2b6c20fd5461c9192baeb54110367",
            "ce65b44b7a8a4a7886807a38668425bf",
            "10c8662d3be54662953fd8a6fe54b207",
            "3237b59b6d6e4339b73badc9638b7e01",
            "bca4467972a740cb887b08350f43cfa1",
            "28d54a65793044259233f6720efb8991",
            "228b0df47de2425dba684435a9619ba6",
            "06fa2de1c471469db18b624eb27fdf33",
            "3b36ed6999944d39b254fd4bcc518628",
            "77fdacf823d04d0c8834f55f9fedddc0",
            "c86f72b092984777b1d769cf9adabe14",
            "f8ae4f1e30d24b70b021ee053baebe25",
            "8009ca8f746441bcbba5d2fd37538858",
            "1c28579c12ba4f39ad156be585ab6ed6",
            "c7c52575e3204f37b0355818e8f7f4d3",
            "836351263c6447ccb52adad431451d79",
            "2ac8396181ca447ea723bf67046ef5f4",
            "e3f427df70e84174892c8e1bdaa29510",
            "662467f4168345519401b000b49314ed",
            "672213502e4a4c20983f9fb34028bb24",
            "929f064f44f9457d972421fb8881414c",
            "a5c5748753884adc8908a9ed832009c3",
            "1b520e1f8d7d4097a1854163d2ad9384",
            "816321c783454f2ab0b1d7d0ecc1f9ca",
            "d97062a4094846eaa8c1fe82699cfc4c",
            "afb04651359d42c09e37136c2158c332",
            "a0de616ee474406f9688dd746f4e06ee",
            "f2570da9854c404facdb6d5010adeef4"
          ]
        },
        "id": "SSA1CV-GHSjO",
        "outputId": "30422c2c-74b2-4a8f-c015-990143e79529"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49a418a2bbcc461dbf52ad194db27c14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08f69bfff88e4d519623a34389959f2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "228b0df47de2425dba684435a9619ba6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3f427df70e84174892c8e1bdaa29510",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/3.09k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import PegasusTokenizer\n",
        "\n",
        "# Load Pegasus tokenizer\n",
        "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(dataframe, max_input_length=1024, max_target_length=128):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for _, row in dataframe.iterrows():\n",
        "        # Tokenize input text (abstract) and truncate/pad\n",
        "        input_text = tokenizer(\n",
        "            row[\"input_text\"],\n",
        "            max_length=max_input_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        # Tokenize target text (title) and truncate/pad\n",
        "        target_text = tokenizer(\n",
        "            row[\"target_text\"],\n",
        "            max_length=max_target_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        inputs.append(input_text)\n",
        "        targets.append(target_text)\n",
        "\n",
        "    return inputs, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUhDw1KDL4EJ",
        "outputId": "8862ca75-7eaf-46f2-8d9a-eceab0bf3b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data preprocessing completed!\n"
          ]
        }
      ],
      "source": [
        "# Preprocess train data\n",
        "train_inputs, train_targets = preprocess_text(train_df)\n",
        "\n",
        "# Preprocess validation data\n",
        "val_inputs, val_targets = preprocess_text(val_df)\n",
        "\n",
        "# Preprocess test data\n",
        "test_inputs, test_targets = preprocess_text(test_df)\n",
        "\n",
        "print(\"Data preprocessing completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vZq1ZEwL8JB",
        "outputId": "f5212156-7e8d-43eb-a885-29a33d2ba052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized datasets saved!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Save preprocessed data as .pt (PyTorch tensor) files\n",
        "torch.save((train_inputs, train_targets), \"train_tokenized.pt\")\n",
        "torch.save((val_inputs, val_targets), \"val_tokenized.pt\")\n",
        "torch.save((test_inputs, test_targets), \"test_tokenized.pt\")\n",
        "\n",
        "print(\"Tokenized datasets saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4a4wvuAMeCS"
      },
      "outputs": [],
      "source": [
        "!mv train_tokenized.pt '/content/drive/My Drive/Scientific Abstract Summarization/'\n",
        "!mv val_tokenized.pt '/content/drive/My Drive/Scientific Abstract Summarization/'\n",
        "!mv test_tokenized.pt '/content/drive/My Drive/Scientific Abstract Summarization/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "978BbuRsMib1",
        "outputId": "09152676-292e-44da-f029-49faf89fc21d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample tokenized input: {'input_ids': tensor([[  202,  1069, 13945,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]])}\n",
            "Sample tokenized target: {'input_ids': tensor([[57394,   113,  6712,  4218, 18580,   454,   889,  1891,  4201,   134,\n",
            "         67240, 13368,   111, 75265, 15269,     1,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "# Check the first tokenized input and target\n",
        "print(\"Sample tokenized input:\", train_inputs[0])\n",
        "print(\"Sample tokenized target:\", train_targets[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhQPSQhik0qC"
      },
      "source": [
        "# Model Design and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGyrAmTmMjs2",
        "outputId": "cf711a59-e705-4918-a7fa-def0c650865d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "31986ec50c2347faa162cd4fb48b2aea",
            "418f40247aa94b7badc2f508b0fe0c70",
            "d26148063a44443bb641c8d29f3214e8",
            "7708fc4cf9114e94b621671035ff0ab1",
            "b359f851d2174aae87545f5471babe97",
            "be754071e73340d78079cbc0507e54da",
            "ac567af6b06145c987cea3c0650e34ef",
            "38a33e51af6d43ceac5bb63d48fdbaa6",
            "fedccbbb6fda47b89e7a01b2f23758a8",
            "82f4e3a7db2f4c4bb9cf5df4b5a70beb",
            "72137058d2ce4b18822d02130dcb3afe",
            "88896919f1734ea0a8a9d5c6818c1fce",
            "d62d79c460ff436094b26eb4da512cb0",
            "dd95174089c743f897b360cdb751f5c6",
            "233b5575da9e452fb1d54bf0303c9106",
            "27f37e86d56543c29ed703296871bc15",
            "f45e3430747442ed9f4fd43611313cec",
            "03ce99d1bb544a7cacbaa48353bad404",
            "f9be77a045994fffab5bb1ed3fdb9bf5",
            "942418a7238c458fb2f90b3fecd8de5b",
            "141c5822a3cc48f7b9d5db3ce3e10ffc",
            "af4f0c3514f04b4688e480f3a5157dc1"
          ]
        },
        "id": "5yRHMHg0MlBS",
        "outputId": "fda504c0-71d9-4afd-8285-6712178f6fff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31986ec50c2347faa162cd4fb48b2aea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88896919f1734ea0a8a9d5c6818c1fce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/260 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "\n",
        "# Load the Pegasus model and tokenizer\n",
        "model_name = \"google/pegasus-large\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzzfdF5tNTxB",
        "outputId": "240a2d28-af10-4447-e1ca-eb44699c745d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=90aea9bd59e22d7b5cc8d45eec56567a3a00f52b2870c7972f34229a1e28306a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPquC_9FMm5X",
        "outputId": "c17d8ada-fbd5-4003-c72f-35ed05f4937d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Train data size: 40000\n",
            "Validation data size: 5000\n",
            "Test data size: 5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 10000/10000 [59:31<00:00,  2.80it/s, Loss=0.262]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Training Loss: 0.5744\n",
            "\n",
            "Epoch 1/3 Validation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 1250/1250 [19:17<00:00,  1.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Validation Loss: 0.2838\n",
            "Epoch 1/3, Validation ROUGE Scores: {'rouge1': 0.413188973979714, 'rouge2': 0.23099091188095836, 'rougeL': 0.37689828229119154, 'rougeLsum': 0.37682674977380726}\n",
            "\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 10000/10000 [59:31<00:00,  2.80it/s, Loss=0.227]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/3, Training Loss: 0.2861\n",
            "\n",
            "Epoch 2/3 Validation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 1250/1250 [19:21<00:00,  1.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/3, Validation Loss: 0.2700\n",
            "Epoch 2/3, Validation ROUGE Scores: {'rouge1': 0.4188902636457766, 'rouge2': 0.2331537289480875, 'rougeL': 0.38055471609687885, 'rougeLsum': 0.3801851400703062}\n",
            "\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 10000/10000 [59:31<00:00,  2.80it/s, Loss=0.45]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/3, Training Loss: 0.2625\n",
            "\n",
            "Epoch 3/3 Validation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 1250/1250 [19:23<00:00,  1.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/3, Validation Loss: 0.2641\n",
            "Epoch 3/3, Validation ROUGE Scores: {'rouge1': 0.4190391689838655, 'rouge2': 0.2358307695685605, 'rougeL': 0.3818613533010472, 'rougeLsum': 0.38152789740839754}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 64, 'num_beams': 8, 'length_penalty': 0.6}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer saved successfully to /content/drive/MyDrive/Scientific Abstract Summarization/fine_tuned_pegasus\n",
            "\n",
            "Evaluating on test dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 1250/1250 [19:08<00:00,  1.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Loss: 0.2671\n",
            "\n",
            "Test ROUGE Scores: {'rouge1': 0.4209434536027694, 'rouge2': 0.2362803918701689, 'rougeL': 0.38329139867115747, 'rougeLsum': 0.38341236962296105}\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers datasets torch evaluate accelerate tqdm\n",
        "\n",
        "# Import libraries\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from evaluate import load\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm  # For progress bars\n",
        "\n",
        "# Enable memory optimization with environment variable\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Scientific Abstract Summarization/train.csv\")\n",
        "val_df = pd.read_csv(\"/content/drive/MyDrive/Scientific Abstract Summarization/val.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Scientific Abstract Summarization/test.csv\")\n",
        "\n",
        "# Verify dataset sizes\n",
        "print(f\"Train data size: {len(train_df)}\")\n",
        "print(f\"Validation data size: {len(val_df)}\")\n",
        "print(f\"Test data size: {len(test_df)}\")\n",
        "\n",
        "# Initialize tokenizer\n",
        "model_name = \"google/pegasus-xsum\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Define a custom dataset class\n",
        "class PegasusDataset(Dataset):\n",
        "    def __init__(self, inputs, targets, tokenizer, max_input_length=512, max_target_length=128):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_length = max_input_length\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.inputs[idx]\n",
        "        target_text = self.targets[idx]\n",
        "\n",
        "        model_inputs = self.tokenizer(\n",
        "            input_text,\n",
        "            max_length=self.max_input_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        labels = self.tokenizer(\n",
        "            target_text,\n",
        "            max_length=self.max_target_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": model_inputs[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": model_inputs[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": labels[\"input_ids\"].squeeze(0),\n",
        "        }\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = PegasusDataset(train_df[\"input_text\"], train_df[\"target_text\"], tokenizer)\n",
        "val_dataset = PegasusDataset(val_df[\"input_text\"], val_df[\"target_text\"], tokenizer)\n",
        "test_dataset = PegasusDataset(test_df[\"input_text\"], test_df[\"target_text\"], tokenizer)\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # Adjust batch size based on memory\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=4)\n",
        "\n",
        "# Load the model\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "# Load the ROUGE metric\n",
        "rouge = load(\"rouge\")\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3  # Train for more epochs for better performance\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "    train_bar = tqdm(train_dataloader, desc=\"Training\", leave=True)\n",
        "\n",
        "    for batch in train_bar:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        train_bar.set_postfix({\"Loss\": loss.item()})\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    decoded_preds, decoded_labels = [], []\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs} Validation\")\n",
        "    val_bar = tqdm(val_dataloader, desc=\"Validating\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_bar:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Compute loss\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            # Generate predictions\n",
        "            generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128)\n",
        "            preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "            targets = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "            decoded_preds.extend(preds)\n",
        "            decoded_labels.extend(targets)\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    rouge_results = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation ROUGE Scores:\", rouge_results)\n",
        "\n",
        "# Save the model\n",
        "output_dir = \"/content/drive/MyDrive/Scientific Abstract Summarization/fine_tuned_pegasus\"\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Model and tokenizer saved successfully to {output_dir}\")\n",
        "\n",
        "# Evaluate on test dataset\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4)\n",
        "model.eval()\n",
        "decoded_preds, decoded_labels = [], []\n",
        "total_test_loss = 0\n",
        "\n",
        "print(\"\\nEvaluating on test dataset...\")\n",
        "test_bar = tqdm(test_dataloader, desc=\"Testing\", leave=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_bar:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Compute loss\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        total_test_loss += outputs.loss.item()\n",
        "\n",
        "        # Generate predictions\n",
        "        generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128)\n",
        "        preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "        targets = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "        decoded_preds.extend(preds)\n",
        "        decoded_labels.extend(targets)\n",
        "\n",
        "avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "# Compute ROUGE scores for test set\n",
        "test_rouge_results = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "print(\"\\nTest ROUGE Scores:\", test_rouge_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IRQe-t-lEhE"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzsJHWOdWNOQ"
      },
      "source": [
        "- Evaluate Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPjol76GNK6Y",
        "outputId": "a6c88f5b-486f-49a5-b374-5b530d6651b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating model on test data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 5000/5000 [36:54<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ROUGE Scores:\n",
            "rouge1: 0.4197\n",
            "rouge2: 0.2348\n",
            "rougeL: 0.3821\n",
            "rougeLsum: 0.3878\n",
            "\n",
            "BLEU Score: 12.232242080689035\n",
            "\n",
            "Predictions and references saved to 'test_predictions.csv'.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install sacrebleu rouge-score nltk evaluate\n",
        "\n",
        "# Import libraries\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "from evaluate import load\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "\n",
        "# Download NLTK tokenizer for BLEU evaluation\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = \"/content/drive/MyDrive/Scientific Abstract Summarization/fine_tuned_pegasus\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_path).to(device)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Load the test dataset\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Scientific Abstract Summarization/test.csv\")\n",
        "\n",
        "# Prepare test data\n",
        "test_inputs = test_df[\"input_text\"].tolist()\n",
        "test_targets = test_df[\"target_text\"].tolist()\n",
        "\n",
        "# Load ROUGE and BLEU metrics\n",
        "rouge = load(\"rouge\")\n",
        "bleu = load(\"sacrebleu\")\n",
        "\n",
        "# Model evaluation\n",
        "model.eval()\n",
        "decoded_preds, decoded_labels = [], []\n",
        "\n",
        "print(\"\\nEvaluating model on test data...\")\n",
        "for input_text, target_text in tqdm(zip(test_inputs, test_targets), total=len(test_inputs), desc=\"Testing\"):\n",
        "    # Tokenize input text\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).input_ids.to(device)\n",
        "\n",
        "    # Generate predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(input_ids=input_ids, max_length=128, num_beams=8, length_penalty=0.6)\n",
        "    preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    # Save predictions and references\n",
        "    decoded_preds.extend(preds)\n",
        "    decoded_labels.append(target_text)\n",
        "\n",
        "# Evaluate ROUGE scores\n",
        "rouge_results = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "print(\"\\nROUGE Scores:\")\n",
        "for metric, score in rouge_results.items():\n",
        "    print(f\"{metric}: {score:.4f}\")  # Directly print the score\n",
        "\n",
        "# Evaluate BLEU scores\n",
        "bleu_results = bleu.compute(predictions=decoded_preds, references=[[ref] for ref in decoded_labels])\n",
        "print(\"\\nBLEU Score:\", bleu_results[\"score\"])\n",
        "\n",
        "# Save the predictions and references for human evaluation\n",
        "output_df = pd.DataFrame({\"Input\": test_inputs, \"Generated Summary\": decoded_preds, \"Reference Summary\": decoded_labels})\n",
        "output_df.to_csv(\"/content/drive/MyDrive/Scientific Abstract Summarization/test_predictions.csv\", index=False)\n",
        "\n",
        "print(\"\\nPredictions and references saved to 'test_predictions.csv'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uEXV8R7swOx"
      },
      "source": [
        "- Evaluate Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70nZ9lzFWe7n",
        "outputId": "eb85f12b-3ee6-4334-8554-5ed25f925dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Displaying a few generated summaries with reference summaries:\n",
            "\n",
            "Example 1:\n",
            "Input Article:\n",
            "  We investigate cosmological particle production in spacetimes where Lorentz\n",
            "invariance emerges in the infrared limit, but is explicitly broken in the\n",
            "ultraviolet regime. Our specific model focuses on the boost subgroup that\n",
            "supports CPT invariance and results in a momentum-dependent dispersion\n",
            "relation. Motivated by previous studies on spacetimes emerging from a\n",
            "microscopic substrate, we show how these modifications naturally lead to\n",
            "momentum-dependent rainbow metrics. Firstly, we investigate the possibility of\n",
            "reproducing cosmological particle production in spacetimes emerging from real\n",
            "Bose gases. We have studied the influence of non-perturbative ultraviolet\n",
            "corrections in time-dependent analogue spacetimes, leading to\n",
            "momentum-dependent emergent rainbow spacetimes. Within certain limits the\n",
            "analogy is sufficiently good to simulate relativistic quantum field theory in\n",
            "time-dependent classical backgrounds, and the quantum effects are approximately\n",
            "robust against the model-dependent modifications. Secondly, we analyze how\n",
            "significantly the particle production process deviates from the common picture.\n",
            "While very low-energy modes do not see the difference at all, some modes\n",
            "\"re-enter the Hubble horizon\" during the inflationary epoch, and extreme\n",
            "ultraviolet modes are completely insensitive to the expansion.\n",
            "\n",
            "\n",
            "Reference Summary:\n",
            "Cosmological particle production in emergent rainbow spacetimes\n",
            "\n",
            "Generated Summary:\n",
            "Momentum-Dependent Emergent Rainbow Spacetimes\n",
            "\n",
            "\n",
            "Example 2:\n",
            "Input Article:\n",
            "  We first summarize work that has been done on the effects of binaries on\n",
            "theoretical population synthesis of stars and stellar phenomena. Next, we\n",
            "highlight the influence of stellar dynamics in young clusters by discussing a\n",
            "few candidate UFOs (unconventionally formed objects) like intermediate mass\n",
            "black holes, Eta Carinae, Zeta Puppis, Gamma Velorum and WR 140.\n",
            "\n",
            "\n",
            "Reference Summary:\n",
            "Binary populations and stellar dynamics in young clusters\n",
            "\n",
            "Generated Summary:\n",
            "Population synthesis of stars and stellar phenomena\n",
            "\n",
            "\n",
            "Example 3:\n",
            "Input Article:\n",
            "  Using the concept of an ideal phase-conjugating mirror we demonstrate that\n",
            "regardless of internal physical mechanism the phase-conjugation of a singular\n",
            "laser beam is accompanied by excitation within the mirror of internal waves\n",
            "which carry doubled angular momentum in order to match angular momentum\n",
            "conservation. For a Brillouin hypersound wavefront-reversal mirror this means\n",
            "that each elementary optical vortex belonging to a speckle pattern emits an\n",
            "acoustical vortex wave with doubled topological charge. The exact spatial\n",
            "profiles of light intensity and the intensity of hypersound in the vicinity of\n",
            "the phase singularity are obtained. These spiral profiles have a form of double\n",
            "helix which rotates with the frequency of sound. An optoacoustic experiment is\n",
            "proposed for visualization of the wavefront reversal of twisted optical beams\n",
            "and tunable twisted sound generation.\n",
            "\n",
            "\n",
            "Reference Summary:\n",
            "Angular Momentum of a Photon and Phase Conjugation\n",
            "\n",
            "Generated Summary:\n",
            "Wavefront reversal of twisted optical beams and tunable twisted sound generation\n",
            "\n",
            "\n",
            "--- Enter a custom input article for summarization (type 'exit' to quit) ---\n",
            "Your Input:  As part of his campaign to reclaim the White House, Donald Trump made clear that in a second term in office, he’d move tens of thousands of federal jobs outside the “Washington swamp” and into “places filled with patriots who love America.”  “This,” Trump said in one campaign video, “is how I will shatter the deep state.”  The relocation of federal jobs outside Washington, DC, was something Trump embarked on near the end of his first term — shifting the headquarters of the Bureau of Land Management about 2,000 miles west to Grand Junction, Colorado.\n",
            "\n",
            "Generated Summary:\n",
            "Moving federal jobs out of Washington, DC\n",
            "\n",
            "--- Enter a custom input article for summarization (type 'exit' to quit) ---\n",
            "Your Input: If you’re looking to catch up on recent shows and movies — including Shogun, The Penguin, and Dune: Part Two — the upcoming holiday weekend is the perfect time to do so. Thankfully, multiple streaming services are slashing subscription prices for Black Friday and Cyber Monday, including Max, Hulu, and others. Right now, for example, you can sign up for a year of Hulu for less than $12. What’s more, you don’t have to be a new subscriber to take advantage of the ongoing promo, which is a rarity in the world of streaming.\n",
            "\n",
            "Generated Summary:\n",
            "Black Friday and Cyber Monday deals on streaming services\n",
            "\n",
            "--- Enter a custom input article for summarization (type 'exit' to quit) ---\n",
            "Your Input: The Bank of England warned on Friday that higher trade barriers could hit global growth and feed uncertainty about inflation, potentially causing volatility in financial markets and pushing up borrowing costs for businesses and consumers. Without specifically referring to the victory of Donald Trump in the U.S. presidential election, the BoE said the financial system could also be impacted by disruption to cross-border capital flows and a reduced ability to diversify risk. \"A reduction in the degree of international policy cooperation could hinder progress by authorities in improving the resilience of the financial system and its ability to absorb future shocks,\" the BoE said in a half-yearly report on the financial system. Asked at a press conference about the likely impact of a second Trump presidency, Bailey repeated his stance that he wanted to see the policies the Trump administration will pursue.\n",
            "\n",
            "Generated Summary:\n",
            "The Bank of England has warned of the potential impact of trade barriers on global growth and inflation\n",
            "\n",
            "--- Enter a custom input article for summarization (type 'exit' to quit) ---\n",
            "Your Input: “Moana 2” set sail at the box office with $13.8 million in preview screenings on Tuesday, ranking as the biggest preview haul in history for Disney Animation. It’s also the biggest pre-Thanksgiving preview bounty and the second-best preview figure of all time for an animated title.  To compare to Disney’s other animated juggernauts, this June’s “Inside Out 2” raked in $13 million in Thursday previews before notching $154 million in its three-day debut, 2019’s “Toy Story 4” brought in $12 million in Thursday previews before launching to $121 million over the three days, while 2019’s “Frozen II” earned $8.5 million in Thursday previews before bowing to $130 million over the weekend prior to Thanksgiving. Pixar’s 2018 sequel “Incredibles 2,” which retains the record for the biggest debut for an animated film, pulled in $18.5 million in Thursday previews before opening to a mighty $183 million over the weekend.\n",
            "\n",
            "Generated Summary:\n",
            "A record-breaking pre-Thanksgiving box office for Disney Animation\n",
            "\n",
            "--- Enter a custom input article for summarization (type 'exit' to quit) ---\n",
            "Your Input: With an 11-1 start, their best in team history, the Detroit Lions continue to end a laundry list of notable droughts.  The Lions, who defeated the Chicago Bears 23-20, had lost seven straight Thanksgiving Day games, which was a point of emphasis throughout the week from coach Dan Campbell.  The Lions dominated the opening half with 18 first downs compared to the Bears' two. Chicago's first first down came with 55 seconds left in the second quarter. The second half was a different story as the Bears stormed back, only to fall short after a sack and an incomplete pass as time expired on the final drive.  Quarterback Jared Goff went 21-for-34 for 221 yards and two touchdowns. The running back duo of Jahmyr Gibbs and David Montgomery combined for 175 yards.  While honoring the late John Madden with jersey patches on their uniforms, the Lions' defense also pitched a first-half shutout in front of a star-studded crowd, which included actor Tim Allen, rapper Eminem, Olympic gymnast Simone Biles and Lions edge rusher Aidan Hutchinson, who wore holiday gear in a suite. \n",
            "\n",
            "Generated Summary:\n",
            "The Detroit Lions beat the Chicago Bears 23-20 to end a seven-game Day game losing streak\n",
            "\n",
            "--- Enter a custom input article for summarization (type 'exit' to quit) ---\n",
            "Your Input: exit\n",
            "Exiting...\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "\n",
        "# Load the saved tokenizer and model\n",
        "output_dir = \"/content/drive/MyDrive/Scientific Abstract Summarization/fine_tuned_pegasus\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(output_dir)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(output_dir)\n",
        "model.eval()\n",
        "\n",
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load the test dataset\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Scientific Abstract Summarization/test.csv\")\n",
        "\n",
        "# Display some generated summaries and compare them to the references\n",
        "print(\"\\nDisplaying a few generated summaries with reference summaries:\")\n",
        "for i in range(3):  # Change the number here to display more/less examples\n",
        "    input_text = test_df.iloc[i][\"input_text\"]\n",
        "    reference_summary = test_df.iloc[i][\"target_text\"]\n",
        "\n",
        "    # Generate summary\n",
        "    inputs = tokenizer(input_text, max_length=512, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=128, num_beams=5, early_stopping=True)\n",
        "    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"\\nExample {i + 1}:\")\n",
        "    print(f\"Input Article:\\n{input_text}\\n\")\n",
        "    print(f\"Reference Summary:\\n{reference_summary}\\n\")\n",
        "    print(f\"Generated Summary:\\n{generated_summary}\\n\")\n",
        "\n",
        "# Allow user to input an article for summary generation\n",
        "while True:\n",
        "    print(\"\\n--- Enter a custom input article for summarization (type 'exit' to quit) ---\")\n",
        "    user_input = input(\"Your Input: \")\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "\n",
        "    # Generate summary for the user input\n",
        "    user_inputs = tokenizer(user_input, max_length=512, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    user_summary_ids = model.generate(user_inputs[\"input_ids\"], max_length=128, num_beams=5, early_stopping=True)\n",
        "    user_generated_summary = tokenizer.decode(user_summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"\\nGenerated Summary:\")\n",
        "    print(user_generated_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G5tMwXStt7G"
      },
      "source": [
        "- https://www.cnn.com/2024/11/29/politics/trump-federal-agency-dc-blm/index.html\n",
        "\n",
        "- https://www.theverge.com/24306534/black-friday-2024-streaming-best-deals-max-hulu-peacock-paramount-plus-cyber-monday\n",
        "\n",
        "- https://www.reuters.com/world/uk/bank-england-warns-risks-rise-global-trade-barriers-2024-11-29/\n",
        "\n",
        "- https://m.imdb.com/news/movie/\n",
        "\n",
        "-https://www.espn.com/nfl/story/_/id/42664634/nfl-week-13-chicago-bears-lose-detroit-lions-thanksgiving-day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEyddxE1tvW2"
      },
      "source": [
        "Scientific Papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVKg66VbxtWo",
        "outputId": "06aebee4-ae1c-4e91-f3f4-336087c10974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Displaying a few generated summaries with reference summaries:\n",
            "\n",
            "Example 1:\n",
            "Input Article:\n",
            "  We investigate cosmological particle production in spacetimes where Lorentz\n",
            "invariance emerges in the infrared limit, but is explicitly broken in the\n",
            "ultraviolet regime. Our specific model focuses on the boost subgroup that\n",
            "supports CPT invariance and results in a momentum-dependent dispersion\n",
            "relation. Motivated by previous studies on spacetimes emerging from a\n",
            "microscopic substrate, we show how these modifications naturally lead to\n",
            "momentum-dependent rainbow metrics. Firstly, we investigate the possibility of\n",
            "reproducing cosmological particle production in spacetimes emerging from real\n",
            "Bose gases. We have studied the influence of non-perturbative ultraviolet\n",
            "corrections in time-dependent analogue spacetimes, leading to\n",
            "momentum-dependent emergent rainbow spacetimes. Within certain limits the\n",
            "analogy is sufficiently good to simulate relativistic quantum field theory in\n",
            "time-dependent classical backgrounds, and the quantum effects are approximately\n",
            "robust against the model-dependent modifications. Secondly, we analyze how\n",
            "significantly the particle production process deviates from the common picture.\n",
            "While very low-energy modes do not see the difference at all, some modes\n",
            "\"re-enter the Hubble horizon\" during the inflationary epoch, and extreme\n",
            "ultraviolet modes are completely insensitive to the expansion.\n",
            "\n",
            "\n",
            "Reference Summary:\n",
            "Cosmological particle production in emergent rainbow spacetimes\n",
            "\n",
            "Generated Summary:\n",
            "Momentum-Dependent Emergent Rainbow Spacetimes\n",
            "\n",
            "\n",
            "Example 2:\n",
            "Input Article:\n",
            "  We first summarize work that has been done on the effects of binaries on\n",
            "theoretical population synthesis of stars and stellar phenomena. Next, we\n",
            "highlight the influence of stellar dynamics in young clusters by discussing a\n",
            "few candidate UFOs (unconventionally formed objects) like intermediate mass\n",
            "black holes, Eta Carinae, Zeta Puppis, Gamma Velorum and WR 140.\n",
            "\n",
            "\n",
            "Reference Summary:\n",
            "Binary populations and stellar dynamics in young clusters\n",
            "\n",
            "Generated Summary:\n",
            "Population synthesis of stars and stellar phenomena\n",
            "\n",
            "\n",
            "Example 3:\n",
            "Input Article:\n",
            "  Using the concept of an ideal phase-conjugating mirror we demonstrate that\n",
            "regardless of internal physical mechanism the phase-conjugation of a singular\n",
            "laser beam is accompanied by excitation within the mirror of internal waves\n",
            "which carry doubled angular momentum in order to match angular momentum\n",
            "conservation. For a Brillouin hypersound wavefront-reversal mirror this means\n",
            "that each elementary optical vortex belonging to a speckle pattern emits an\n",
            "acoustical vortex wave with doubled topological charge. The exact spatial\n",
            "profiles of light intensity and the intensity of hypersound in the vicinity of\n",
            "the phase singularity are obtained. These spiral profiles have a form of double\n",
            "helix which rotates with the frequency of sound. An optoacoustic experiment is\n",
            "proposed for visualization of the wavefront reversal of twisted optical beams\n",
            "and tunable twisted sound generation.\n",
            "\n",
            "\n",
            "Reference Summary:\n",
            "Angular Momentum of a Photon and Phase Conjugation\n",
            "\n",
            "Generated Summary:\n",
            "Wavefront reversal of twisted optical beams and tunable twisted sound generation\n",
            "\n",
            "\n",
            "--- Enter a custom input article for summarization (type 'exit' to quit) ---\n",
            "Your Input: In this work, a novel system (method) for sleep quality analysis is proposed. Its purpose is to assist an alternative non-contact method for detecting and diagnosing sleep related disorders based on acoustic signal processing. In this work, audio signals of 145 patients with obstructive sleep apnea were recorded (more than 1000 hours) in a sleep laboratory and analyzed. The method is based on the assumption that during sleep the respiratory efforts are more periodically patterned and consistent relative to a waking state; furthermore, the sound intensity of those efforts is higher, making the pattern more noticeable relative to the background noise level. The system was trained on 50 subjects and validated on 95 subjects. The system accuracy for detecting sleep/wake state is 82.1% (epoch by epoch), resulting in 3.9% error (difference) in detecting sleep latency, 11.4% error in estimating total sleep time, and 11.4% error in estimating sleep efficiency. \n",
            "\n",
            "Generated Summary:\n",
            "A novel system for sleep quality analysis based on acoustic signal processing\n",
            "\n",
            "--- Enter a custom input article for summarization (type 'exit' to quit) ---\n",
            "Your Input: Match fixing in cricket is a fraudulent activity involving captain of the team, few key players, umpires, officials, bookies, middle men and gangsters. To perform match fixing in cricket, they form a criminal network with each of them acting as a node and association between these nodes acting as edges. To analyze this network concepts like using graph mining, link mining, community mining and algorithmic design notation like greedy technique are applied. Participants in a cricket match like captain, umpires, players, officials are called internal participants share vital game plan information from dressing room with bookies, middlemen and gangsters. Participants like bookies, middlemen and gangsters who perform match fixing with the support of internal participants are called external participants and they use information given to them by internal participants to conduct betting and fixing activities. Some important game plan information are pitch report, weather report, team composition, team batting strategy, field placement, and team bowling strategy. In this paper we focus our attention on match fixing network analysis using internal participants. \n",
            "\n",
            "Generated Summary:\n",
            "Match fixing network analysis using internal participants\n",
            "\n",
            "--- Enter a custom input article for summarization (type 'exit' to quit) ---\n",
            "Your Input: The restoration of walking capability is a key goal after stroke, traumatic brain injury and spinal cord injury. Conventional training methods, e.g. treadmill training, require great physical effort from the therapists to assist the patient. A robotic training machine would be desirable in order to improve the training and to relieve the therapists. In addition to the general robot kinematics design issues, the designer of such a machine has to take into account several considerations specific to patient treatment in a rehabilitation clinic. Such a robotic walking simulator for neurological rehabilitation has been designed by our group and a prototype is currently being built. It will enable the therapist to let the machine move the patients feet on programmable foot trajectories (e.g. walking on plane floor, stepping stairs up and down, walking on rough surfaces, disturbances during walking). Therefore the patients feet will be fixed on two separate footplates mounted on the robot endeffectors. The highly dynamic robotic system can be used as a universal walking simulator, not only for rehabilitation purposes, i.e. as a haptic foot device for a variety of virtual ground conditions.\n",
            "\n",
            "Generated Summary:\n",
            "A robotic walking simulator for neurological rehabilitation\n",
            "\n",
            "--- Enter a custom input article for summarization (type 'exit' to quit) ---\n",
            "Your Input: exit\n",
            "Exiting...\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "\n",
        "# Load the saved tokenizer and model\n",
        "output_dir = \"/content/drive/MyDrive/Scientific Abstract Summarization/fine_tuned_pegasus\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(output_dir)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(output_dir)\n",
        "model.eval()\n",
        "\n",
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load the test dataset\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Scientific Abstract Summarization/test.csv\")\n",
        "\n",
        "# Display some generated summaries and compare them to the references\n",
        "print(\"\\nDisplaying a few generated summaries with reference summaries:\")\n",
        "for i in range(3):  # Change the number here to display more/less examples\n",
        "    input_text = test_df.iloc[i][\"input_text\"]\n",
        "    reference_summary = test_df.iloc[i][\"target_text\"]\n",
        "\n",
        "    # Generate summary\n",
        "    inputs = tokenizer(input_text, max_length=512, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=128, num_beams=5, early_stopping=True)\n",
        "    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"\\nExample {i + 1}:\")\n",
        "    print(f\"Input Article:\\n{input_text}\\n\")\n",
        "    print(f\"Reference Summary:\\n{reference_summary}\\n\")\n",
        "    print(f\"Generated Summary:\\n{generated_summary}\\n\")\n",
        "\n",
        "# Allow user to input an article for summary generation\n",
        "while True:\n",
        "    print(\"\\n--- Enter a custom input article for summarization (type 'exit' to quit) ---\")\n",
        "    user_input = input(\"Your Input: \")\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "\n",
        "    # Generate summary for the user input\n",
        "    user_inputs = tokenizer(user_input, max_length=512, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    user_summary_ids = model.generate(user_inputs[\"input_ids\"], max_length=128, num_beams=5, early_stopping=True)\n",
        "    user_generated_summary = tokenizer.decode(user_summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"\\nGenerated Summary:\")\n",
        "    print(user_generated_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-p2_VEnE7Bd"
      },
      "source": [
        "- https://sci-hub.ru/https://doi.org/10.1109/EMBC.2012.6346760\n",
        "\n",
        "- https://sci-hub.ru/https://doi.org/10.1109/RTEICT.2017.8256758\n",
        "\n",
        "- https://sci-hub.ru/https://doi.org/10.1109/IEMBS.2002.1053320\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q0yxM_3IHuu"
      },
      "source": [
        "- Upload and Summarize PDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9d6gtKmKRUT"
      },
      "source": [
        "Yoga for depression: The research evidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "f7ccY2Lf2-81",
        "outputId": "95bbfd77-50d9-4bca-975e-b694c3a0c4d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7577da73-56e4-43b8-96b2-9fcbe967a22b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7577da73-56e4-43b8-96b2-9fcbe967a22b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 1-s2.0-S0165032705002570-main.pdf to 1-s2.0-S0165032705002570-main.pdf\n",
            "\n",
            "Extracted Text:\n",
            " Review\n",
            "Yoga for depression: The research evidence\n",
            "Karen Pilkingtona,b,*, Graham Kirkwooda,1, Hagen Rampesc, Janet Richardsona,d\n",
            "aResearch Council for Complementary Medicine, London, UK\n",
            "bSchool of Integrated Health, University of Westminster, 115 New Cavendish Street, London W1W 6UW, UK\n",
            "cBarnet, Enfield and Haringey Mental Health NHS Trust, Northwest Community Mental Health Team, Edgware, Middlesex, UK\n",
            "dHealth and Social Work, University of Plymouth and Research Council for Complementary Medicine ...\n",
            "\n",
            "Generated Summary:\n",
            " Systematic review of research evidence on the effectiveness of yoga for the treatment of depression\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install PyPDF2 transformers\n",
        "\n",
        "# Import required libraries\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "import torch\n",
        "import PyPDF2\n",
        "from google.colab import files\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the fine-tuned Pegasus model and tokenizer\n",
        "output_dir = \"/content/drive/MyDrive/Scientific Abstract Summarization/fine_tuned_pegasus\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(output_dir)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(output_dir)\n",
        "model.to(device)\n",
        "\n",
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as pdf_file:\n",
        "        reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Function to summarize text using Pegasus\n",
        "def summarize_text(text, max_input_length=512, max_summary_length=128):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=max_summary_length,\n",
        "        num_beams=5,\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode and return the summary\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Upload the PDF\n",
        "uploaded_file = files.upload()\n",
        "\n",
        "# Extract text from the uploaded PDF\n",
        "pdf_path = list(uploaded_file.keys())[0]\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "print(\"\\nExtracted Text:\\n\", pdf_text[:500], \"...\")  # Print the first 500 characters of the text\n",
        "\n",
        "# Summarize the extracted text\n",
        "summary = summarize_text(pdf_text)\n",
        "print(\"\\nGenerated Summary:\\n\", summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7NUKYQkKObC"
      },
      "source": [
        "AI ethics in computational psychiatry: From the neuroscience of\n",
        "consciousness to the ethics of consciousness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "LLK7BX_uIJm1",
        "outputId": "a5b11d59-bf17-479c-e90a-5d75b8d30680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-448ad40f-e94d-4943-a63a-657ccfee5fa6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-448ad40f-e94d-4943-a63a-657ccfee5fa6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 1-s2.0-S0166432821005921-main.pdf to 1-s2.0-S0166432821005921-main.pdf\n",
            "\n",
            "Extracted Text:\n",
            " Behavioural Brain Research 420 (2022) 113704\n",
            "Available online 4 December 2021\n",
            "0166-4328/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).AI ethics in computational psychiatry: From the neuroscience of \n",
            "consciousness to the ethics of consciousness \n",
            "Wanja Wiesea,*, Karl J. Fristonb \n",
            "aInstitute of Philosophy II, Ruhr University Bochum, Universit atsstra ße 150, 44780 Bochum, Germany \n",
            "bWellcome Cent ...\n",
            "\n",
            "Generated Summary:\n",
            " Ethical considerations from AI ethics in computational psychiatry\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install PyPDF2 transformers\n",
        "\n",
        "# Import required libraries\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "import torch\n",
        "import PyPDF2\n",
        "from google.colab import files\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the fine-tuned Pegasus model and tokenizer\n",
        "output_dir = \"/content/drive/MyDrive/Scientific Abstract Summarization/fine_tuned_pegasus\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(output_dir)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(output_dir)\n",
        "model.to(device)\n",
        "\n",
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as pdf_file:\n",
        "        reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Function to summarize text using Pegasus\n",
        "def summarize_text(text, max_input_length=512, max_summary_length=128):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=max_summary_length,\n",
        "        num_beams=5,\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode and return the summary\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Upload the PDF\n",
        "uploaded_file = files.upload()\n",
        "\n",
        "# Extract text from the uploaded PDF\n",
        "pdf_path = list(uploaded_file.keys())[0]\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "print(\"\\nExtracted Text:\\n\", pdf_text[:500], \"...\")  # Print the first 500 characters of the text\n",
        "\n",
        "# Summarize the extracted text\n",
        "summary = summarize_text(pdf_text)\n",
        "print(\"\\nGenerated Summary:\\n\", summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEI52M3PKHTe"
      },
      "source": [
        "A polymerase chain reaction experiment using Escherichia coli and Mars\n",
        "sand simulant for detection and analysis of extraterrestrial life"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "kwsgczj9Jj_Y",
        "outputId": "e08ca145-c77e-4260-98f0-48a84053731a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-189a6822-34bf-4ab3-8844-b777d96f7c3a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-189a6822-34bf-4ab3-8844-b777d96f7c3a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 1-s2.0-S2214552424000610-main.pdf to 1-s2.0-S2214552424000610-main.pdf\n",
            "\n",
            "Extracted Text:\n",
            " Life Sciences in Space Research 42 (2024) 84–90\n",
            "Available online 23 May 2024\n",
            "2214-5524/© 2024 The Committee on Space Research (COSPAR). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license\n",
            "(http://creativecommons.org/licenses/by-nc-nd/4.0/ ).A polymerase chain reaction experiment using Escherichia coli and Mars \n",
            "sand simulant for detection and analysis of extraterrestrial life \n",
            "Keigo Enyaa,b,*, Satoshi Sasakic, Taiki Kuniedac \n",
            "aInstitute of Space & Astronautica ...\n",
            "\n",
            "Generated Summary:\n",
            " A chain reaction experiment using Escherichia coli and Mars sand simulant for detection and analysis of extraterrestrial life\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install PyPDF2 transformers\n",
        "\n",
        "# Import required libraries\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "import torch\n",
        "import PyPDF2\n",
        "from google.colab import files\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the fine-tuned Pegasus model and tokenizer\n",
        "output_dir = \"/content/drive/MyDrive/Scientific Abstract Summarization/fine_tuned_pegasus\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(output_dir)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(output_dir)\n",
        "model.to(device)\n",
        "\n",
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as pdf_file:\n",
        "        reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Function to summarize text using Pegasus\n",
        "def summarize_text(text, max_input_length=512, max_summary_length=128):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=max_summary_length,\n",
        "        num_beams=5,\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode and return the summary\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Upload the PDF\n",
        "uploaded_file = files.upload()\n",
        "\n",
        "# Extract text from the uploaded PDF\n",
        "pdf_path = list(uploaded_file.keys())[0]\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "print(\"\\nExtracted Text:\\n\", pdf_text[:500], \"...\")  # Print the first 500 characters of the text\n",
        "\n",
        "# Summarize the extracted text\n",
        "summary = summarize_text(pdf_text)\n",
        "print(\"\\nGenerated Summary:\\n\", summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjnG6PVzMR0f"
      },
      "source": [
        "# Code for Deployment Readiness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0Ae12rJMW-o"
      },
      "source": [
        "- Export the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h_wf0S1KGPG",
        "outputId": "77d08c69-9096-4963-adaf-cf2668c6e0cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading the fine-tuned model and tokenizer...\n",
            "Saving the deployment-ready model to: /content/drive/MyDrive/Scientific Abstract Summarization/deployment_model\n",
            "Model and tokenizer successfully saved to /content/drive/MyDrive/Scientific Abstract Summarization/deployment_model\n"
          ]
        }
      ],
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "\n",
        "# Define the model directory where the fine-tuned model is saved\n",
        "fine_tuned_model_dir = \"/content/drive/MyDrive/Scientific Abstract Summarization/fine_tuned_pegasus\"\n",
        "\n",
        "# Define the directory to save the deployment-ready model and tokenizer\n",
        "deployment_model_dir = \"/content/drive/MyDrive/Scientific Abstract Summarization/deployment_model\"\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "print(\"Loading the fine-tuned model and tokenizer...\")\n",
        "tokenizer = PegasusTokenizer.from_pretrained(fine_tuned_model_dir)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(fine_tuned_model_dir)\n",
        "\n",
        "# Save the model and tokenizer in the Hugging Face format for deployment\n",
        "print(f\"Saving the deployment-ready model to: {deployment_model_dir}\")\n",
        "model.save_pretrained(deployment_model_dir)\n",
        "tokenizer.save_pretrained(deployment_model_dir)\n",
        "\n",
        "print(f\"Model and tokenizer successfully saved to {deployment_model_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLqs_6F_X1bL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0219f4c1d0b74e9a978a6a4f18335737": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ce99d1bb544a7cacbaa48353bad404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06fa2de1c471469db18b624eb27fdf33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ae4f1e30d24b70b021ee053baebe25",
            "placeholder": "​",
            "style": "IPY_MODEL_8009ca8f746441bcbba5d2fd37538858",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "08f69bfff88e4d519623a34389959f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed0c9f8b82cf44108aa3ccac2418e96d",
              "IPY_MODEL_acff8a28306b49abab1542cc6eaa955c",
              "IPY_MODEL_dcd981f091d6462fb45827d4aaca4506"
            ],
            "layout": "IPY_MODEL_0219f4c1d0b74e9a978a6a4f18335737"
          }
        },
        "0a000c1185c54521a9e5a505285bd38b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10c8662d3be54662953fd8a6fe54b207": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "141c5822a3cc48f7b9d5db3ce3e10ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b520e1f8d7d4097a1854163d2ad9384": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c28579c12ba4f39ad156be585ab6ed6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228b0df47de2425dba684435a9619ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06fa2de1c471469db18b624eb27fdf33",
              "IPY_MODEL_3b36ed6999944d39b254fd4bcc518628",
              "IPY_MODEL_77fdacf823d04d0c8834f55f9fedddc0"
            ],
            "layout": "IPY_MODEL_c86f72b092984777b1d769cf9adabe14"
          }
        },
        "233b5575da9e452fb1d54bf0303c9106": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_141c5822a3cc48f7b9d5db3ce3e10ffc",
            "placeholder": "​",
            "style": "IPY_MODEL_af4f0c3514f04b4688e480f3a5157dc1",
            "value": " 260/260 [00:00&lt;00:00, 23.6kB/s]"
          }
        },
        "27f37e86d56543c29ed703296871bc15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28d54a65793044259233f6720efb8991": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ac8396181ca447ea723bf67046ef5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31986ec50c2347faa162cd4fb48b2aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_418f40247aa94b7badc2f508b0fe0c70",
              "IPY_MODEL_d26148063a44443bb641c8d29f3214e8",
              "IPY_MODEL_7708fc4cf9114e94b621671035ff0ab1"
            ],
            "layout": "IPY_MODEL_b359f851d2174aae87545f5471babe97"
          }
        },
        "3237b59b6d6e4339b73badc9638b7e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36acdffb2bd747d0ba213737dac91298": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a33e51af6d43ceac5bb63d48fdbaa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a3d805e7c75403db77201ea34e0f7d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a000c1185c54521a9e5a505285bd38b",
            "placeholder": "​",
            "style": "IPY_MODEL_9f12dda087bc4996ab951930220e72c3",
            "value": " 88.0/88.0 [00:00&lt;00:00, 6.29kB/s]"
          }
        },
        "3b36ed6999944d39b254fd4bcc518628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c28579c12ba4f39ad156be585ab6ed6",
            "max": 65,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7c52575e3204f37b0355818e8f7f4d3",
            "value": 65
          }
        },
        "418f40247aa94b7badc2f508b0fe0c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be754071e73340d78079cbc0507e54da",
            "placeholder": "​",
            "style": "IPY_MODEL_ac567af6b06145c987cea3c0650e34ef",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "49a418a2bbcc461dbf52ad194db27c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abbafe1804d5406eb9fee475f9876794",
              "IPY_MODEL_778b2d57370f4d0a9bbdb56582b3761a",
              "IPY_MODEL_3a3d805e7c75403db77201ea34e0f7d1"
            ],
            "layout": "IPY_MODEL_ac351ec33b994f4c9655cefa021f95b8"
          }
        },
        "5bf2b6c20fd5461c9192baeb54110367": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6190d91fe7d748bb921ae6e7ce4054a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "662467f4168345519401b000b49314ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b520e1f8d7d4097a1854163d2ad9384",
            "placeholder": "​",
            "style": "IPY_MODEL_816321c783454f2ab0b1d7d0ecc1f9ca",
            "value": "config.json: 100%"
          }
        },
        "672213502e4a4c20983f9fb34028bb24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d97062a4094846eaa8c1fe82699cfc4c",
            "max": 3094,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afb04651359d42c09e37136c2158c332",
            "value": 3094
          }
        },
        "72137058d2ce4b18822d02130dcb3afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7708fc4cf9114e94b621671035ff0ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82f4e3a7db2f4c4bb9cf5df4b5a70beb",
            "placeholder": "​",
            "style": "IPY_MODEL_72137058d2ce4b18822d02130dcb3afe",
            "value": " 2.28G/2.28G [00:10&lt;00:00, 223MB/s]"
          }
        },
        "778b2d57370f4d0a9bbdb56582b3761a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f72916c0369245c79dbc015247288b52",
            "max": 88,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6190d91fe7d748bb921ae6e7ce4054a8",
            "value": 88
          }
        },
        "77fdacf823d04d0c8834f55f9fedddc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_836351263c6447ccb52adad431451d79",
            "placeholder": "​",
            "style": "IPY_MODEL_2ac8396181ca447ea723bf67046ef5f4",
            "value": " 65.0/65.0 [00:00&lt;00:00, 5.97kB/s]"
          }
        },
        "8009ca8f746441bcbba5d2fd37538858": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "816321c783454f2ab0b1d7d0ecc1f9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82f4e3a7db2f4c4bb9cf5df4b5a70beb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836351263c6447ccb52adad431451d79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88896919f1734ea0a8a9d5c6818c1fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d62d79c460ff436094b26eb4da512cb0",
              "IPY_MODEL_dd95174089c743f897b360cdb751f5c6",
              "IPY_MODEL_233b5575da9e452fb1d54bf0303c9106"
            ],
            "layout": "IPY_MODEL_27f37e86d56543c29ed703296871bc15"
          }
        },
        "929f064f44f9457d972421fb8881414c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0de616ee474406f9688dd746f4e06ee",
            "placeholder": "​",
            "style": "IPY_MODEL_f2570da9854c404facdb6d5010adeef4",
            "value": " 3.09k/3.09k [00:00&lt;00:00, 296kB/s]"
          }
        },
        "942418a7238c458fb2f90b3fecd8de5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f12dda087bc4996ab951930220e72c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0de616ee474406f9688dd746f4e06ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c5748753884adc8908a9ed832009c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbafe1804d5406eb9fee475f9876794": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36acdffb2bd747d0ba213737dac91298",
            "placeholder": "​",
            "style": "IPY_MODEL_da756576955f4ef7a598cd3f500a96f4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ac351ec33b994f4c9655cefa021f95b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac567af6b06145c987cea3c0650e34ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acff8a28306b49abab1542cc6eaa955c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10c8662d3be54662953fd8a6fe54b207",
            "max": 1912529,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3237b59b6d6e4339b73badc9638b7e01",
            "value": 1912529
          }
        },
        "af4f0c3514f04b4688e480f3a5157dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afb04651359d42c09e37136c2158c332": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b359f851d2174aae87545f5471babe97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bca4467972a740cb887b08350f43cfa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be754071e73340d78079cbc0507e54da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c52575e3204f37b0355818e8f7f4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c86f72b092984777b1d769cf9adabe14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce65b44b7a8a4a7886807a38668425bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d26148063a44443bb641c8d29f3214e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38a33e51af6d43ceac5bb63d48fdbaa6",
            "max": 2275327883,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fedccbbb6fda47b89e7a01b2f23758a8",
            "value": 2275327883
          }
        },
        "d62d79c460ff436094b26eb4da512cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f45e3430747442ed9f4fd43611313cec",
            "placeholder": "​",
            "style": "IPY_MODEL_03ce99d1bb544a7cacbaa48353bad404",
            "value": "generation_config.json: 100%"
          }
        },
        "d97062a4094846eaa8c1fe82699cfc4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da756576955f4ef7a598cd3f500a96f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcd981f091d6462fb45827d4aaca4506": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bca4467972a740cb887b08350f43cfa1",
            "placeholder": "​",
            "style": "IPY_MODEL_28d54a65793044259233f6720efb8991",
            "value": " 1.91M/1.91M [00:00&lt;00:00, 22.2MB/s]"
          }
        },
        "dd95174089c743f897b360cdb751f5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9be77a045994fffab5bb1ed3fdb9bf5",
            "max": 260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_942418a7238c458fb2f90b3fecd8de5b",
            "value": 260
          }
        },
        "e3f427df70e84174892c8e1bdaa29510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_662467f4168345519401b000b49314ed",
              "IPY_MODEL_672213502e4a4c20983f9fb34028bb24",
              "IPY_MODEL_929f064f44f9457d972421fb8881414c"
            ],
            "layout": "IPY_MODEL_a5c5748753884adc8908a9ed832009c3"
          }
        },
        "ed0c9f8b82cf44108aa3ccac2418e96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bf2b6c20fd5461c9192baeb54110367",
            "placeholder": "​",
            "style": "IPY_MODEL_ce65b44b7a8a4a7886807a38668425bf",
            "value": "spiece.model: 100%"
          }
        },
        "f2570da9854c404facdb6d5010adeef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f45e3430747442ed9f4fd43611313cec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72916c0369245c79dbc015247288b52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ae4f1e30d24b70b021ee053baebe25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9be77a045994fffab5bb1ed3fdb9bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fedccbbb6fda47b89e7a01b2f23758a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
